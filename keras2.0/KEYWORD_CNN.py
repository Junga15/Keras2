<CNN(Convolutional Neural Network)> => 평생먹거리!!
#keras39

CNN의 기본개념: 특성을 자른다.조각조각내는것 => 코딩시 1줄 삽입함 =>이미지만 CNN이 아님
Conv20(10,(2,2),input_shape=(5,5,1))
      #10  #가로세로 2씩 자름 #1은 검정(컬러일경우3),즉 맨마지막은 컬러값
      #이미지의 총량은 5X5,이미지컬러값RGB는 1
      #(N,5,5,1) => (N,4,4,10) N:배치, 왼쪽 두번째5:행, 두번쨰5:열 1:채널,피터
      #5X5개씩 잘라서 N장이 나옴, 이것이 하나의 레이어 
      # => 한번의 컨볼류션을 지나 전체 데이터의 개수 N 장동일,잘린 것 중 하나를 4X4로 자름
           뒤가 10인 이유는 인풋노드=특성을 증폭시켜주는 것을 의미함, 1이면 특성증폭이 적다.

      #첫번째 예제 28X28X1

필터
커널 컨볼류션 신경망 이야기 참고


이미지 데이터
:이미지 한 픽셀당 수치가 다름, 머신은 그림을 아주 세밀하게 조각조각내서
특성을 뽑음
수치가 높으면 특성이 높다.(ex>선생님 사람 그림 중 눈부분) 배경은 0에 가깝다.
곱하면 특성은 더욱 하면 강해지고 특성이 없는 부분은 더 없어진다.

이미지를 조각조각 잘라서 특성 뽑고
이미지를 조각조각 잘라서 특성 뽑고...계속 반복 연산함.

이미지는 100픽셀X100픽셀X3(컬러값)Xn개
y값 사람(1)인지 말(0)인지 판단
======================================================================================

Fully Connected Layer1 만으로 구성된 인공 신경망의 입력 데이터는 1차원(배열) 형태로 한정됩니다. 
한 장의 컬러 사진은 3차원 데이터입니다. 
배치 모드에 사용되는 여러장의 사진은 4차원 데이터입니다. 
사진 데이터로 전연결(FC, Fully Connected) 신경망을 학습시켜야 할 경우에, 
3차원 사진 데이터를 1차원으로 평면화시켜야 합니다. 
사진 데이터를 평면화 시키는 과정에서 공간 정보가 손실될 수밖에 없습니다. 
결과적으로 이미지 공간 정보 유실로 인한 정보 부족으로 인공 신경망이 특징을 추출 및 학습이 
비효율적이고 정확도를 높이는데 한계가 있습니다. 
이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 바로 CNN(Convolutional Neural Network)입니다.

CNN(Convolutional Neural Network)은 기존 Fully Connected Neural Network와 비교하여 다음과 같은 차별성을 갖습니다.

각 레이어의 입출력 데이터의 형상 유지
이미지의 공간 정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식
복수의 필터로 이미지의 특징 추출 및 학습
추출한 이미지의 특징을 모으고 강화하는 Pooling 레이어
필터를 공유 파라미터로 사용하기 때문에, 일반 인공 신경망과 비교하여 학습 파라미터가 매우 적음